# -*- coding: utf-8 -*-
"""Domain adaptation hashing old file

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1l0kMtTeIgb3AL4u4A01kp3hUn-kcUtmI
"""

!wget https://download1514.mediafire.com/9rs9rmrxmacg/7yv132lgn1v267r/vlcs.tar.gz

!tar -xzvf vlcs.tar.gz

import torchvision
from torchvision import transforms
img_size = 64
c_train_dataset = torchvision.datasets.ImageFolder(root='VLCS/CALTECH/train',
                transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),)
l_train_dataset = torchvision.datasets.ImageFolder(root='VLCS/LABELME/train',
                                                   transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),)
v_train_dataset = torchvision.datasets.ImageFolder(root='VLCS/PASCAL/train',
                                                   transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),)
s_train_dataset = torchvision.datasets.ImageFolder(root='VLCS/SUN/train',
                                                   transform=transforms.Compose([transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),)

from torch.utils.data import DataLoader, ConcatDataset, TensorDataset
import torch
from torchvision import transforms, datasets

dataloader = torch.utils.data.DataLoader(
    ConcatDataset([c_train_dataset, s_train_dataset, l_train_dataset]),
    shuffle=True,
    batch_size = 32
)

test_loader = torch.utils.data.DataLoader(
    v_train_dataset,
    shuffle=True,
    batch_size = 32
)

mean = 0
for i, (imgs, labels) in enumerate(dataloader):
  if i == len(dataloader)-1:
    break
  mean = mean + imgs
mean = mean.mean()
mean = mean / len(dataloader)

std = 0
for i, (imgs, labels) in enumerate(dataloader):
  if i == len(dataloader)-1:
    break
  std = std + imgs
std = std.std()
std = std / len(dataloader)

# coding: utf-8
import torch
import numpy as np
import pickle
import os
import sys
import errno
import os.path as osp

def wasserstein_loss(y_true, y_pred):
 return torch.mean(y_true * y_pred)

def mkdir_if_missing(directory):
    if not osp.exists(directory):
        try:
            os.makedirs(directory)
        except OSError as e:
            if e.errno != errno.EEXIST:
                raise


def normalized(a, axis=-1, order=2):
    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))
    l2[l2==0] = 1
    return a / np.expand_dims(l2, axis)


def deprocess_image(x):
    x -= x.mean()
    x /= (x.std() + 1e-5)
    x *= 0.1
    x = np.clip(x, -1, 1)
    return x


class AverageMeter(object):
    """Computes and stores the average and current value.

       Code imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262
    """
    def __init__(self):
        self.reset()

    def reset(self):
        self.val = 0
        self.avg = 0
        self.sum = 0
        self.count = 0

    def update(self, val, n=1):
        self.val = val
        self.sum += val * n
        self.count += n
        self.avg = self.sum / self.count


class Logger(object):
    """
    Write console output to external text file.

    Code imported from https://github.com/Cysu/open-reid/blob/master/reid/utils/logging.py.
    """
    def __init__(self, fpath=None):
        self.console = sys.stdout
        self.file = None
        if fpath is not None:
            mkdir_if_missing(os.path.dirname(fpath))
            self.file = open(fpath, 'w')

    def __del__(self):
        self.close()

    def __enter__(self):
        pass

    def __exit__(self, *args):
        self.close()

    def write(self, msg):
        self.console.write(msg)
        if self.file is not None:
            self.file.write(msg)

    def flush(self):
        self.console.flush()
        if self.file is not None:
            self.file.flush()
            os.fsync(self.file.fileno())

    def close(self):
        self.console.close()
        if self.file is not None:
            self.file.close()


def compute_result(dataloader, net, device):

    """
    return hashing codes of data with shape (N, len_bits) and its labels (N, )
    """
    hash_codes = []
    label = []
    for i, (imgs, cls, *_) in enumerate(dataloader):
        imgs, cls = imgs.to(device), cls.to(device)
        hash_values = net(imgs)
        hash_codes.append(hash_values.data)
        label.append(cls)

    hash_codes = torch.cat(hash_codes)
    B = torch.where(hash_codes > 0.0, torch.tensor([1.0]).cuda(), torch.tensor([-1.0]).cuda())

    return B, torch.cat(label)


def compute_topK(trn_binary, tst_binary, trn_label, tst_label, device, top_list):

    """
    compute mean precision of returned top-k results based on Hamming ranking
    """

    top_p = torch.Tensor(tst_binary.size(0), len(top_list)).to(device)

    for i in range(tst_binary.size(0)):
        query_label, query_binary = tst_label[i], tst_binary[i]
        _, query_result = torch.sum((query_binary != trn_binary).long(), dim=1).sort()
        for j, top in enumerate(top_list):
            top_result = query_result[:top]
            top_correct = (query_label == trn_label[top_result]).float()
            N_top = torch.sum(top_correct)
            top_p[i, j] = 1.0*N_top/top

    top_pres = top_p.mean(dim=0).cpu().numpy()

    return top_pres


def compute_mAP(trn_binary, tst_binary, trn_label, tst_label, device):

    AP = []
    for i in range(tst_binary.size(0)):
        query_label, query_binary = tst_label[i], tst_binary[i]
        print("query_label, query_binary", query_label.size(), query_binary.size())
        _, query_result = torch.sum((query_binary != trn_binary).long(), dim=1).sort()
        correct = (query_label == trn_label[query_result]).float()
        N = torch.sum(correct)
        Ns = torch.arange(1, N+1).float().to(device)
        index = (torch.nonzero(correct, as_tuple=False)+1)[:, 0].float()
        AP.append(torch.mean(Ns / index))

    mAP = torch.mean(torch.Tensor(AP))
    return mAP

def compute_score(trn_binary, tst_binary, trn_label, tst_label, device):

    AP = []
    Pr  = []
    Rr = []
    for i in range(tst_binary.size(0)):
        query_label, query_binary = tst_label[i], tst_binary[i]
        print("query_label, query_binary", query_label.size(), query_binary.size())
        _, query_result = torch.sum((query_binary != trn_binary).long(), dim=1).sort()
        correct = (query_label == trn_label[query_result]).float()
        false = (query_label != trn_label[query_result]).float()
        N = torch.sum(correct)
        Ns = torch.arange(1, N+1).float().to(device)
        M = torch.sum(false)
        Ms = torch.arange(1, M+1).float().to(device)

        index = (torch.nonzero(correct, as_tuple=False)+1)[:, 0].float()
        index1 = (torch.nonzero(false, as_tuple=False)+1)[:, 0].float()
        print("Ns, index, index1", Ns.size(), index.size(), index1.size)
        Pr.append(torch.mean(Ns/index))
        Rr.append(torch.mean(Ns/index1))
        AP.append(torch.mean(Ns / index))

    P   = torch.Tensor(AP)
    R = torch.tensor(Rr)
    mAP = torch.mean(torch.Tensor(AP))
    return mAP, Pr, R


def EncodingOnehot(target, nclasses):
    target_onehot = torch.Tensor(target.size(0), nclasses)
    target_onehot.zero_()
    target_onehot.scatter_(1, target.cpu().view(-1, 1), 1)
    return target_onehot

# Commented out IPython magic to ensure Python compatibility.
## change feature extractor RESNET (approve 33.68 amazon-->webcam)
#adding adam optimizer,
import argparse
import os
import numpy as np
import math
# from utils import *
import torchvision.transforms as transforms
from torchvision.utils import save_image

from torch.utils.data import DataLoader
from torchvision import datasets
from torch.autograd import Variable
import torch.backends.cudnn as cudnn
from torchvision import models

import torch.nn as nn
import torch.nn.functional as F
import torch

os.makedirs("images", exist_ok=True)

n_epochs = 300 # parser.add_argument("--n_epochs", type=int, default=200, help="number of epochs of training")
batch_size = 32               # parser.add_argument("--batch_size", type=int, default=32, help="size of the batches")
lr = 0.0002 # parser.add_argument("--lr", type=float, default=0.0002, help="adam: learning rate")
b1 = 0.5 # parser.add_argument("--b1", type=float, default=0.5, help="adam: decay of first order momentum of gradient")
b2 = 0.999 # parser.add_argument("--b2", type=float, default=0.999, help="adam: decay of first order momentum of gradient")
n_cpu = 8 # parser.add_argument("--n_cpu", type=int, default=8, help="number of cpu threads to use during batch generation")
latent_dim = 100 # parser.add_argument("--latent_dim", type=int, default=100, help="dimensionality of the latent space")
n_classes = 31 # parser.add_argument("--n_classes", type=int, default=10, help="number of classes for dataset")
img_size = 128 # parser.add_argument("--img_size", type=int, default=32, help="size of each image dimension")
channels = 1 # parser.add_argument("--channels", type=int, default=1, help="number of image channels")
sample_interval = 400 # parser.add_argument("--sample_interval", type=int, default=400, help="interval between image sampling")
beta1 = 0.5
bits = 16
img_shape = (channels, img_size, img_size)
threshold = 60

cuda = True if torch.cuda.is_available() else False
cudnn.benchmark = True

# bits = 48

class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()

        self.label_emb = nn.Embedding(n_classes, n_classes)

        self.fc1 = nn.Linear(latent_dim + n_classes, 256*16*16)
        self.fc_bn = nn.BatchNorm1d(256*16*16)
        self.lr = nn.LeakyReLU()

        self.conv1 = nn.Conv2d(
                in_channels=256,
                out_channels=128,
                kernel_size=5,
                stride=1,
                padding=2,
                bias=False)
        self.bn2d1 = nn.BatchNorm2d(128)

        self.conv2 = nn.ConvTranspose2d(
                in_channels=128,
                out_channels=64,
                kernel_size=4,
                stride=2,
                padding=1,
                bias=False)
        self.bn2d2 = nn.BatchNorm2d(64)

        self.conv3 = nn.ConvTranspose2d(
                in_channels=64,
                out_channels=1,
                kernel_size=4,
                stride=2,
                padding=1,
                bias=False)
        self.tanh = nn.Tanh()
        self.model = nn.Sequential()
    def forward(self, noise, labels):
        # Concatenate label embedding and image to produce input
        gen_input = torch.cat((self.label_emb(labels), noise), -1)

        img = self.fc1(gen_input)
        img = self.fc_bn(img)
        img = self.lr(img)

        img = img.view((-1, 256,16,16))

        img = self.conv1(img)
        img = self.bn2d1(img)
        img = self.lr(img)

        img = self.conv2(img)
        img = self.bn2d2(img)
        img = self.lr(img)

        img = self.conv3(img)
        img = self.tanh(img)

        return img


class Discriminator(nn.Module):
    def __init__(self, bits):
        super(Discriminator, self).__init__()
        self.label_embedding = nn.Embedding(n_classes, n_classes)

        self.conv1 = nn.Conv2d(1, 32, kernel_size=11, stride=4, padding=2)
        self.relu1 = nn.ReLU(inplace=True)
        self.maxPool1 = nn.MaxPool2d(kernel_size=1, stride=2)

        self.conv2 = nn.Conv2d(32, 96, kernel_size=5, padding=2)
        self.relu2 = nn.ReLU(inplace=True)
        self.maxPool2 = nn.MaxPool2d(kernel_size=1, stride=2)

        self.conv3 = nn.Conv2d(96, 192, kernel_size=3, padding=1)
        self.relu3 = nn.ReLU(inplace=True)

        self.conv4 = nn.Conv2d(192, 128, kernel_size=3, padding=1)
        self.relu4 = nn.ReLU(inplace=True)

        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        self.relu5 = nn.ReLU(inplace=True)

        self.maxPool3 = nn.MaxPool2d(kernel_size=1, stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))

        self.drop1 = nn.Dropout(p=0.5)
        self.linear1 = nn.Linear(128 * 6 * 6, 2048)

        self.relu6 = nn.ReLU(inplace=True)

        self.drop2 = nn.Dropout(p=0.5)
        self.linear2 = nn.Linear(2048, bits)        #24 bits

        self.relu7 = nn.ReLU(inplace=True)
        self.linear3 = nn.Linear(bits, 1)           #24 bits
        # self.soft = nn.functional.softmax()

    def forward(self, x: torch.Tensor,labels,flag) -> torch.Tensor:
        a = self.label_embedding(labels)
        # print(x.size())
        a = nn.ConstantPad1d((0,4065),0)(a)
        b = 0
        if flag==0:
          b = a.view(-1,1,64,64)
        else:
          b = a.view(1,1,64,64)
        # print(b.size())
        # print(x.size())
        x = torch.cat((x, b), -1)
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.maxPool1(x)
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.maxPool2(x)
        x = self.conv3(x)
        x = self.relu3(x)
        x = self.conv4(x)
        x = self.relu4(x)
        x = self.conv5(x)
        x = self.relu5(x)
        x = self.maxPool3(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.drop1(x)
        x = self.linear1(x)
        x = self.relu6(x)
        x = self.drop2(x)
        x = self.linear2(x)
        y = self.relu7(x)
        y = self.linear3(y)
        y = torch.sigmoid(y)
        return x,y

class ClassWiseLoss(nn.Module):
    '''
    Normalized gaussian-based cross-entropy loss
    '''

    def __init__(self, num_classes, bit_length, inv_var=1, update_grad=False, use_gpu=True):
        super(ClassWiseLoss, self).__init__()
        self.num_classes = num_classes
        self.bits = bit_length
        self.use_gpu = use_gpu
        self.sigma = inv_var
        self.update = update_grad   # update by intra-class hashing outputs or gradient descent
        if update_grad:
            self.centers = nn.Parameter(torch.randn(self.num_classes, self.bits).cuda())

    def forward(self, x, labels, centroids=None):
        """
        Args:
            x: batch_size * feat_dim
            labels: (batch_size, )
        """
        if not self.update:
            self.centers = centroids
        batch_size = x.size(0)
        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \
                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()

        distmat.addmm_(x, self.centers.t(), beta=1, alpha=-2)  # shape of (bs * num_bit)
        numer = torch.exp(-0.5*self.sigma*distmat)
        denumer = numer.sum(dim=1, keepdim=True)
        dist_div = numer/(denumer+1e-6)
        classes = torch.arange(self.num_classes).long()
        if self.use_gpu:
            classes = classes.cuda()
        labels = labels.view(-1, 1).expand(batch_size, self.num_classes)
        mask = labels.eq(classes.expand(batch_size, self.num_classes))

        dist_log = torch.log(dist_div+1e-6) * mask.float()

        loss = -dist_log.sum() / batch_size

        return loss

adversarial_loss = torch.nn.MSELoss()

class hashing_net(nn.Module):
    def __init__(self, bit):
        super(hashing_net, self).__init__()
        self.bit = bit

    def create_model(self):

        # model = models.alexnet(pretrained = True, progress = True)
        # model = models.resnet152(pretrained = True, progress = True)

        model = models.resnet152(pretrained=True, progress=True)
        num_features = model.fc.in_features
        model.fc = nn.Linear(num_features, self.bit)

        # model.features[0] = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)
        # model.features[2] = nn.MaxPool2d(kernel_size=1, stride=2)
        # model.features[5] = nn.MaxPool2d(kernel_size=1, stride=2)
        # model.features[12] = nn.MaxPool2d(kernel_size=1, stride=2)
        # model.classifier[6] = nn.Linear(4096, self.bit)
        return model

model = hashing_net(100).create_model()
# Initialize generator and discriminator
generator = Generator()
discriminator = Discriminator(bits)

if cuda:
    generator.cuda()
    discriminator.cuda()
    adversarial_loss.cuda()

# Optimizers
optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))

FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor
LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor

def adjust_learning_rate(optimizer, epoch):
    """Sets the learning rate to the initial LR decayed by 10 every 50 epochs"""

    lrs = lr * (0.1 ** (epoch // 50))
    for i, param_group in enumerate(optimizer.param_groups):
        param_group['lr'] = lrs  # lr
    return lrs


def centers_computing(model, data_loader, classes, length):

    U = []
    labels = []
    centers = torch.Tensor(classes, length).cuda()
    model.eval()
    for iter, (data, target, *_) in enumerate(data_loader):
        data_input, target = data.cuda(), target.cuda()
        data_input = transforms.functional.rgb_to_grayscale(data_input)
        output, y = model(data_input,target,0)
        U.append(output.data)
        labels.append(target)
    U = torch.cat(U).cuda()
    labels = torch.cat(labels).squeeze().cuda()
    for i in torch.unique(labels).tolist():
        index_list = torch.nonzero(labels == i).squeeze()
        centers[i, :] = U[index_list, :].sum(dim=0) / index_list.size(0)

    return centers

def compute_mAP(trn_binary, tst_binary, trn_label, tst_label, device):

    AP = []
    for i in range(tst_binary.size(0)):
        query_label, query_binary = tst_label[i], tst_binary[i]
        _, query_result = torch.sum((query_binary != trn_binary).long(), dim=1).sort()
        correct = (query_label == trn_label[query_result]).float()
        N = torch.sum(correct)
        Ns = torch.arange(1, N+1).float().to(device)
        index = (torch.nonzero(correct, as_tuple=False)+1)[:, 0].float()
        AP.append(torch.mean(Ns / index))

    mAP = torch.mean(torch.Tensor(AP))
    return mAP

def compute_result(dataloader, net, device):

    """
    return hashing codes of data with shape (N, len_bits) and its labels (N, )
    """
    hash_codes = []
    label = []
    for i, (imgs, cls, *_) in enumerate(dataloader):
        if len(dataloader)==313:
            if i==312:
              break
        imgs, cls = imgs.to(device), cls.to(device)
        imgs = transforms.functional.rgb_to_grayscale(imgs)
        hash_values, y = net(imgs, cls,0)
        hash_codes.append(hash_values)
        label.append(cls)
    # print("hash_codes", hash_codes)
    hash_codes = torch.cat(hash_codes)
    B = torch.where(hash_codes > 0.0, torch.tensor([1.0]).cuda(), torch.tensor([-1.0]).cuda())

    return B, torch.cat(label)
def sample_image(n_row, batches_done):
    """Saves a grid of generated digits ranging from 0 to n_classes"""
    # Sample noise
    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row**2, latent_dim))))
    # Get labels ranging from 0 to n_classes for n rows
    labels = np.array([num for _ in range(n_row) for num in range(n_row)])
    labels = Variable(LongTensor(labels))
    gen_imgs = generator(z, labels)
    save_image(gen_imgs.data, "images/%d.png" % batches_done, nrow=n_row, normalize=True)

device = "cuda:0" if torch.cuda.is_available() else "cpu"
discriminator = torch.nn.DataParallel(discriminator).to(device)
centers = torch.randn(31, bits).cuda().detach()
criterion_beacon = ClassWiseLoss(num_classes=31, bit_length=bits, update_grad=False, use_gpu=True)
# optimizer = torch.optim.SGD([
#             {'params': discriminator.module.parameters(), 'weight_decay': 5e-4},
#             {'params':  criterion_beacon.parameters(), 'weight_decay': 5e-4}], lr = lr, momentum=0.9)

optimizer = torch.optim.Adam([
            {'params': discriminator.module.parameters(), 'weight_decay': 5e-4},
            {'params':  criterion_beacon.parameters(), 'weight_decay': 5e-4}], lr = lr, betas=(beta1, 0.999))

# optimizerD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))
# optimizerG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))
# ----------
#  Training
# ----------
best_MAP = 0
for epoch in range(n_epochs):
    torch.autograd.set_detect_anomaly(True)
    discriminator.train()
    adjust_learning_rate(optimizer, epoch)
    dcwh_loss = AverageMeter()
    iterable = iter(enumerate(test_loader))

    for i, (imgs, labels) in enumerate(dataloader):
        imgs = transforms.functional.rgb_to_grayscale(imgs)

        batch_size = imgs.shape[0]

        # Adversarial ground truths
        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)
        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)

        # Configure input
        real_imgs = Variable(imgs.type(FloatTensor))
        labels = Variable(labels.type(LongTensor))

        # -----------------
        #  Train Generator
        # -----------------
        if epoch>threshold and epoch%2!=0:
          print(epoch)
          inputs, targets = imgs.cuda(), labels.cuda()
          optimizer.zero_grad()
          features, y = discriminator(inputs, targets,0)
          if not False:
              loss_beacon = criterion_beacon(features, targets, centers)
          else:
              loss_beacon = criterion_beacon(features, targets)
          adv_loss = adversarial_loss(y,valid)
          loss_cubic = F.relu(-1.1 - features).sum() + F.relu(features - 1.1).sum() / len(inputs)     # Stage I: Establishment with cubic constraint
          Bbatch = torch.sign(features)
          loss_l3 = (Bbatch - features).pow(2).sum() / len(inputs)    # Stage II: Refine with vertex constraint
          loss = loss_beacon + (10 * loss_cubic + 0.01 * loss_l3) / len(inputs)
          # loss = (loss-adv_loss)
          dcwh_loss.update(loss.item(), len(inputs))
          # print(loss)
          loss.backward()
          optimizer.step()

        elif epoch>threshold and epoch%2==0:
          print(epoch)
          optimizer.zero_grad()
          z = 0
          gen_labels = 0
          if True:
            z = Variable(FloatTensor(np.random.normal(0.6187, 0.2555, (batch_size, latent_dim))))
            gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))
          else:
            i, (imgg,labels) = next(iterable)
            imgg = transforms.functional.rgb_to_grayscale(imgg)
            z = model(imgg).cuda()
            gen_labels = labels.cuda()

        # Generate a batch of images
          gen_imgs = generator(z, gen_labels)
          # print(gen_imgs.size())
          gen_imgs, gen_labels = gen_imgs.cuda(), gen_labels.cuda()
          features,y = discriminator(gen_imgs, gen_labels,0)
          # features, y = discriminator(inputs, targets,0)
          if not False:
              loss_beacon = criterion_beacon(features, gen_labels, centers)
          else:
              loss_beacon = criterion_beacon(features, gen_labels)
          # adv_loss = adversarial_loss(y,valid)
          loss_cubic = F.relu(-1.1 - features).sum() + F.relu(features - 1.1).sum() / len(gen_imgs)     # Stage I: Establishment with cubic constraint
          Bbatch = torch.sign(features)
          loss_l3 = (Bbatch - features).pow(2).sum() / len(gen_imgs)    # Stage II: Refine with vertex constraint
          loss = loss_beacon + (10 * loss_cubic + 0.01 * loss_l3) / len(gen_imgs)
          # loss = (loss-adv_loss)
          dcwh_loss.update(loss.item(), len(gen_imgs))
          # print(loss)
          loss.backward()
          optimizer.step()

        # -----------------
        #  Train Generator
        # -----------------
        else:
          optimizer_G.zero_grad()

          # Sample noise and labels as generator input
          z = 0
          gen_labels = 0
          if True:
            z = Variable(FloatTensor(np.random.normal(0.6187, 0.2555, (batch_size, latent_dim))))
            gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))
          else:
            i, (imgg,labels) = next(iterable)
            imgg = transforms.functional.rgb_to_grayscale(imgg)
            z = model(imgg).cuda()
            gen_labels = labels.cuda()

          # Generate a batch of images
          gen_imgs = generator(z, gen_labels)

          # Loss measures generator's ability to fool the discriminator
          validity,y = discriminator(gen_imgs, gen_labels,0)
          Bbatch = torch.sign(validity)
          loss_l3 = (Bbatch - validity).pow(2).sum() / len(gen_imgs)    # Stage II: Refine with vertex constraint
          g_loss = adversarial_loss(y, valid) + 0.1*loss_l3+wasserstein_loss(fake, y)

          g_loss.backward()
          optimizer_G.step()

          # # ---------------------
          # #  Train Discriminator
          # # ---------------------

          optimizer_D.zero_grad()

          # Loss for real images
          validity_real,y_real = discriminator(real_imgs, labels,0)
          Bbatch = torch.sign(validity_real)
          loss_l3 = (Bbatch - validity_real).pow(2).sum() / len(real_imgs)
          # print(validity_real)
          d_real_loss = adversarial_loss(y_real, valid) + 0.1*loss_l3

          # Loss for fake images
          validity_fake,y_fake = discriminator(gen_imgs.detach(), gen_labels,0)
          Bbatch = torch.sign(validity_fake)
          loss_l3 = (Bbatch - validity_fake).pow(2).sum() / len(gen_imgs)
          d_fake_loss = adversarial_loss(y_fake, fake) + 0.1*loss_l3

          # Total discriminator loss
          d_loss = (d_real_loss + d_fake_loss) / 2 + (wasserstein_loss(fake,y_fake)-wasserstein_loss(valid, y_real))/2
          # print(i)
          # print(loss.item())
          d_loss.backward()
          optimizer_D.step()

          print(
              "[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]"
#               % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())
          )

        batches_done = epoch * len(dataloader) + i
        if batches_done % sample_interval == 0:
            sample_image(n_row=31, batches_done=batches_done)
    if (epoch+1) % 2 == 0 and epoch>60:  # Update centers periodically each two epochs
        discriminator.eval()
        centers = centers_computing(discriminator, dataloader, 31, bits)
    if (epoch+1) % 1 == 0:
            discriminator.eval()
            with torch.no_grad():
                trainB, train_labels = compute_result(dataloader, discriminator, device)

                testB, test_labels = compute_result(test_loader, discriminator, device)
                mAP = compute_mAP(trainB, testB, train_labels, test_labels, device)
                # mAP1, Pr, R = compute_score(trainB, testB, train_labels, test_labels, device)
                if mAP > best_MAP:
                    best_MAP = mAP

            print("[mAP: %.2f%%]" % (float(mAP)*100.0))
            print("[best_mAP: %.2f%%]" % (float(best_MAP)*100.0))
            # print("[Pr:%.2f%%]"%(float(Pr)*100.0))
            # print("[Recall: %.2f%%]" % (float(R)*100.0))
# torch.save(discriminator.state_dict(),'new')

